{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had two major areas of discussion this week.  The first was all about how to work with string data - parsing and splitting strings using basic string fuctions as well as more complex string matching using regular expressions.  The second was a basic introduction to Pandas with a few different examples of how to load data into Pandas and then visualize it using graphs (histogram, distribution, scatter, bar, timeseries).\n",
    "\n",
    "* 36.1 - 1 point\n",
    "* 36.2 - 1 point\n",
    "* 38.1 - 3 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 36.1 String Manipulation\n",
    "\n",
    "Write a function that will parse an address that includes one or two parts of street information, a city, a state, and a zip code -- all separated by commas.  You can assume that commas won't appear as part of the address information, only as a delimiter.  Here are some examples:\n",
    "\n",
    "823 Pebble Street, St. Louis, MO 63105\n",
    "\n",
    "91 Cityplace, Suite #33, St. Louis, MO 63144\n",
    "\n",
    "81234 Homeroad, Kansas City, MO 62441\n",
    "\n",
    "\n",
    "The output you should generate will be a dictionary with the following possible items.\n",
    "\n",
    "```\n",
    "{\n",
    "  'street1': '91 Cityplace',\n",
    "  'street2': 'Suite #33',\n",
    "  'city': 'St. Louis',\n",
    "  'state': 'MO',\n",
    "  'zip': '63122'\n",
    "}\n",
    "```\n",
    "\n",
    "Declare your function like this:\n",
    "```\n",
    "parse_address(address)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_address(address):\n",
    "    \"\"\" This function takes any address as an input and outputs a dictionary which consists of the \n",
    "    components of that address (i.e street, state, zip code). An example is shown below:\n",
    "    \n",
    "    >>>> parse_address('5824 Nolensville Pike, Nashville, TN 37211')\n",
    "    >>>{'street1': '5824 Nolensville Pike',\n",
    "     'city': 'Nashville',\n",
    "     'state': 'TN',\n",
    "     'zip code': '37211'}\n",
    "    \"\"\"\n",
    "    a=address.split(',')\n",
    "    if len(a)==3:\n",
    "        d=a[2].split()\n",
    "        address_dic={\n",
    "        'street1': a[0],\n",
    "        'city': a[1].strip(),\n",
    "        'state': d[0],\n",
    "        'zip code': d[1]\n",
    "        }\n",
    "    else:\n",
    "        a=address.split(',')\n",
    "        d=a[3].split()\n",
    "        address_dic={\n",
    "        'street1': a[0],\n",
    "        'street2': a[1].strip(),\n",
    "        'city': a[2].strip(),\n",
    "        'state': d[0],\n",
    "        'zip code': d[1]\n",
    "        }\n",
    "        \n",
    "    return address_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_address('1309 Bell Rd #216, Antioch, TN 37013')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 36.2 Test the Address Parser\n",
    "\n",
    "Now write a series of good tests to ensure that your addres parser is going to work with a variety of different inputs.  Include at least 5 different examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_dic=parse_address('4140 Washington Blvd, Apt #108, St. Louis, MO 63108')\n",
    "assert(parse_address('4140 Washington Blvd, Apt #108, St. Louis, MO 63108')==address_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_dic=parse_address('91 Cityplace, Suite #33, St. Louis, MO 63144')\n",
    "assert(parse_address('91 Cityplace, Suite #33, St. Louis, MO 63144')==address_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_dic=parse_address('81234 Homeroad, Kansas City, MO 62441')\n",
    "assert(parse_address('81234 Homeroad, Kansas City, MO 62441')==address_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_dic=parse_address('408 Thompson Ln, Nashville, TN 37211')\n",
    "assert(parse_address('408 Thompson Ln, Nashville, TN 37211')==address_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_dic=parse_address('1375 Buena Vista Dr, Lake Buena Vista, FL 32830')\n",
    "assert(parse_address('1375 Buena Vista Dr, Lake Buena Vista, FL 32830')==address_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 38.1 COVID-19 Trend Data\n",
    "\n",
    "Since we're dealing with a global pandemic right now, probably good to go ahead and do some anlysis with that data.  Take a look at what's here: https://ourworldindata.org/covid-sources-comparison\n",
    "\n",
    "Near the middle of the page, there are two charts with some data.  On the left is \"positive cases\" and on the right is \"deaths.\"  Both charts have a button that says \"Data.\"  What you will do below is write a series of Python commands (doesn't need to be in a function) to read that data and produce a simple timeseries chart using the information from John's Hopkins.  Your code will need to read the data, possibly do some reformatting, and then produce a simple timeseries chart.\n",
    "\n",
    "(Unfortunately, the tools used on this website don't make it easy to link to and directly download the data, so I've placed a copy in `/data/covid19.xlsx` for you to access.  This file came from one of the underlying sources: https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "d = pd.read_excel('/data/covid19.xlsx', quotechar='\"')\n",
    "d = d[d['Cases']!=0]\n",
    "d=d.dropna()\n",
    "corona_virus = pd.DataFrame()\n",
    "corona_virus['DateRep'] = pd.to_datetime(d['DateRep'], format='%Y-%m-%d')\n",
    "corona_virus['Cases'] = d['Cases'].astype(int)\n",
    "\n",
    "data = corona_virus.groupby(['DateRep']).sum()\n",
    "data.sort_index().cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hint that you might find helpful while working on this is that the data in this file is the number of cases each week, not the running total.  You will want to plot a running total.\n",
    "\n",
    "To do so, pandas has a `.cumsum()` method that you can use after doing a `groupby` and a `.sum()` somewhat similar to the last example of the pandas-viz.ipynb file (except in that example, it's doing a `mean()` instead of `sum()` and a `rolling()` instead of `cumsum()`.)  This link might also provide a little guidance: https://stackoverflow.com/questions/48739374/pandas-plot-cumulative-sum-of-counters-over-time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Challenges\n",
    "\n",
    "Take the same data, but not start looking at it by country.  Do some groupbys.\n",
    "\n",
    "Or take the same data and look at the mortality rate (deaths / total reported cases) and see how that is different by country or trending over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "ad= pd.read_excel('/data/covid19.xlsx', quotechar='\"')\n",
    "data = pd.DataFrame()\n",
    "data['Countries and territories'] = d['Countries and territories']\n",
    "data['Cases'] = d['Cases'].astype(int)\n",
    "\n",
    "g = data.groupby(['Countries and territories']).mean().plot(style='.', alpha=.1)\n",
    "g.set_ylim(0,100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad= pd.read_excel('/data/covid19.xlsx', quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "data2=d[['Countries and territories', 'Cases']]\n",
    "sns.barplot(x='Countries and territories', y='Cases', data=data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[['Countries and territories', 'Cases']].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
